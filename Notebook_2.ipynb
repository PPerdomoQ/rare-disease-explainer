{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rk_5URyCK63A"
   },
   "source": [
    "## **Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQ21iS3262v5"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtjvIEaVQtjt"
   },
   "source": [
    "## **Drug-Target Information**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGC_KFmPSw5s"
   },
   "source": [
    "### **Load Files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwqroCPyReTj"
   },
   "source": [
    "Load the information from Drug Central and Monarch: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPmLX3DLQzcq"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('drug.target.interaction.tsv', header=0, sep='\\t')\n",
    "nodes = pd.read_csv('graph_nodes_v2022-01-11.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGeqKSxBKwbI"
   },
   "outputs": [],
   "source": [
    "df['NEW_ID'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IECsy_n6S2Dc"
   },
   "source": [
    "### **Uniprot to Monarch IDs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKEuDtSnSEad"
   },
   "source": [
    "Use Uniprot API to obtain new target IDs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LvE2nEHcoIn",
    "outputId": "2321fb73-5160-4044-b73f-772220afd9c1"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import json\n",
    "import zlib\n",
    "from xml.etree import ElementTree\n",
    "from urllib.parse import urlparse, parse_qs, urlencode\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "\n",
    "POLLING_INTERVAL = 3\n",
    "API_URL = \"https://rest.uniprot.org\"\n",
    "\n",
    "\n",
    "retries = Retry(total=5, backoff_factor=0.25, status_forcelist=[500, 502, 503, 504])\n",
    "session = requests.Session()\n",
    "session.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "\n",
    "\n",
    "def check_response(response):\n",
    "    try:\n",
    "        response.raise_for_status()\n",
    "    except requests.HTTPError:\n",
    "        print(response.json())\n",
    "        raise\n",
    "\n",
    "\n",
    "def submit_id_mapping(from_db, to_db, ids):\n",
    "    request = requests.post(\n",
    "        f\"{API_URL}/idmapping/run\",\n",
    "        data={\"from\": from_db, \"to\": to_db, \"ids\": \",\".join(ids)},\n",
    "    )\n",
    "    check_response(request)\n",
    "    return request.json()[\"jobId\"]\n",
    "\n",
    "\n",
    "def get_next_link(headers):\n",
    "    re_next_link = re.compile(r'<(.+)>; rel=\"next\"')\n",
    "    if \"Link\" in headers:\n",
    "        match = re_next_link.match(headers[\"Link\"])\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "\n",
    "\n",
    "def check_id_mapping_results_ready(job_id):\n",
    "    while True:\n",
    "        request = session.get(f\"{API_URL}/idmapping/status/{job_id}\")\n",
    "        check_response(request)\n",
    "        j = request.json()\n",
    "        if \"jobStatus\" in j:\n",
    "            if j[\"jobStatus\"] == \"RUNNING\":\n",
    "                print(f\"Retrying in {POLLING_INTERVAL}s\")\n",
    "                time.sleep(POLLING_INTERVAL)\n",
    "            else:\n",
    "                raise Exception(j[\"jobStatus\"])\n",
    "        else:\n",
    "            return bool(j[\"results\"] or j[\"failedIds\"])\n",
    "\n",
    "\n",
    "def get_batch(batch_response, file_format, compressed):\n",
    "    batch_url = get_next_link(batch_response.headers)\n",
    "    while batch_url:\n",
    "        batch_response = session.get(batch_url)\n",
    "        batch_response.raise_for_status()\n",
    "        yield decode_results(batch_response, file_format, compressed)\n",
    "        batch_url = get_next_link(batch_response.headers)\n",
    "\n",
    "\n",
    "def combine_batches(all_results, batch_results, file_format):\n",
    "    if file_format == \"json\":\n",
    "        for key in (\"results\", \"failedIds\"):\n",
    "            if key in batch_results and batch_results[key]:\n",
    "                all_results[key] += batch_results[key]\n",
    "    elif file_format == \"tsv\":\n",
    "        return all_results + batch_results[1:]\n",
    "    else:\n",
    "        return all_results + batch_results\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def get_id_mapping_results_link(job_id):\n",
    "    url = f\"{API_URL}/idmapping/details/{job_id}\"\n",
    "    request = session.get(url)\n",
    "    check_response(request)\n",
    "    return request.json()[\"redirectURL\"]\n",
    "\n",
    "\n",
    "def decode_results(response, file_format, compressed):\n",
    "    if compressed:\n",
    "        decompressed = zlib.decompress(response.content, 16 + zlib.MAX_WBITS)\n",
    "        if file_format == \"json\":\n",
    "            j = json.loads(decompressed.decode(\"utf-8\"))\n",
    "            return j\n",
    "        elif file_format == \"tsv\":\n",
    "            return [line for line in decompressed.decode(\"utf-8\").split(\"\\n\") if line]\n",
    "        elif file_format == \"xlsx\":\n",
    "            return [decompressed]\n",
    "        elif file_format == \"xml\":\n",
    "            return [decompressed.decode(\"utf-8\")]\n",
    "        else:\n",
    "            return decompressed.decode(\"utf-8\")\n",
    "    elif file_format == \"json\":\n",
    "        return response.json()\n",
    "    elif file_format == \"tsv\":\n",
    "        return [line for line in response.text.split(\"\\n\") if line]\n",
    "    elif file_format == \"xlsx\":\n",
    "        return [response.content]\n",
    "    elif file_format == \"xml\":\n",
    "        return [response.text]\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def get_xml_namespace(element):\n",
    "    m = re.match(r\"\\{(.*)\\}\", element.tag)\n",
    "    return m.groups()[0] if m else \"\"\n",
    "\n",
    "\n",
    "def merge_xml_results(xml_results):\n",
    "    merged_root = ElementTree.fromstring(xml_results[0])\n",
    "    for result in xml_results[1:]:\n",
    "        root = ElementTree.fromstring(result)\n",
    "        for child in root.findall(\"{http://uniprot.org/uniprot}entry\"):\n",
    "            merged_root.insert(-1, child)\n",
    "    ElementTree.register_namespace(\"\", get_xml_namespace(merged_root[0]))\n",
    "    return ElementTree.tostring(merged_root, encoding=\"utf-8\", xml_declaration=True)\n",
    "\n",
    "\n",
    "def print_progress_batches(batch_index, size, total):\n",
    "    n_fetched = min((batch_index + 1) * size, total)\n",
    "    print(f\"Fetched: {n_fetched} / {total}\")\n",
    "\n",
    "\n",
    "def get_id_mapping_results_search(url):\n",
    "    parsed = urlparse(url)\n",
    "    query = parse_qs(parsed.query)\n",
    "    file_format = query[\"format\"][0] if \"format\" in query else \"json\"\n",
    "    if \"size\" in query:\n",
    "        size = int(query[\"size\"][0])\n",
    "    else:\n",
    "        size = 500\n",
    "        query[\"size\"] = size\n",
    "    compressed = (\n",
    "        query[\"compressed\"][0].lower() == \"true\" if \"compressed\" in query else False\n",
    "    )\n",
    "    parsed = parsed._replace(query=urlencode(query, doseq=True))\n",
    "    url = parsed.geturl()\n",
    "    request = session.get(url)\n",
    "    check_response(request)\n",
    "    results = decode_results(request, file_format, compressed)\n",
    "    total = int(request.headers[\"x-total-results\"])\n",
    "    print_progress_batches(0, size, total)\n",
    "    for i, batch in enumerate(get_batch(request, file_format, compressed), 1):\n",
    "        results = combine_batches(results, batch, file_format)\n",
    "        print_progress_batches(i, size, total)\n",
    "    if file_format == \"xml\":\n",
    "        return merge_xml_results(results)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_id_mapping_results_stream(url):\n",
    "    if \"/stream/\" not in url:\n",
    "        url = url.replace(\"/results/\", \"/results/stream/\")\n",
    "    request = session.get(url)\n",
    "    check_response(request)\n",
    "    parsed = urlparse(url)\n",
    "    query = parse_qs(parsed.query)\n",
    "    file_format = query[\"format\"][0] if \"format\" in query else \"json\"\n",
    "    compressed = (\n",
    "        query[\"compressed\"][0].lower() == \"true\" if \"compressed\" in query else False\n",
    "    )\n",
    "    return decode_results(request, file_format, compressed)\n",
    "\n",
    "\n",
    "job_id = submit_id_mapping(\n",
    "    from_db=\"UniProtKB_AC-ID\", to_db=\"HGNC\", ids=[\"Q12809\"]\n",
    ")\n",
    "if check_id_mapping_results_ready(job_id):\n",
    "    link = get_id_mapping_results_link(job_id)\n",
    "    results = get_id_mapping_results_search(link)\n",
    "    # Equivalently using the stream endpoint which is more demanding\n",
    "    # on the API and so is less stable:\n",
    "    # results = get_id_mapping_results_stream(link)\n",
    "\n",
    "print(results)\n",
    "# {'results': [{'from': 'P05067', 'to': 'CHEMBL2487'}], 'failedIds': ['P12345']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "MkzNbzpGeATl",
    "outputId": "4dd5dd12-ba95-4c53-db34-4f1ba93221a6"
   },
   "outputs": [],
   "source": [
    "for i in range(0, df.shape[0]): \n",
    "  print('Going through row', i, ' out of', df.shape[0])\n",
    "\n",
    "  id = df['ACCESSION'][i].split('|')[0]\n",
    "  print(id)\n",
    "  org = df['ORGANISM'][i]\n",
    "  print(org)\n",
    "\n",
    "  if org == 'Homo sapiens': \n",
    "    to = 'HGNC'\n",
    "    pre = ''\n",
    "  elif org == 'Rattus norvegicus': \n",
    "    to = 'RGD'\n",
    "    pre = 'RGD:'\n",
    "  elif org == 'Mus musculus': \n",
    "    to = 'MGI'\n",
    "    pre = ''\n",
    "  elif org == 'Drosophila melanogaster':\n",
    "    to = 'FlyBase'\n",
    "    pre = 'FlyBase'\n",
    "  elif org == 'Caenorhabditis elegans': \n",
    "    to = 'WormBase'\n",
    "    pre = 'WormBase:'\n",
    "  elif org == 'Danio rerio': \n",
    "    to = 'ZFIN'\n",
    "    pre = 'ZFIN:'\n",
    "  elif org == 'Saccharomyces cerevisiae': \n",
    "    to = 'SGD'\n",
    "    pre = 'SGD:'\n",
    "  else:   \n",
    "    to = 'Ensembl'\n",
    "    pre = 'ENSEMBL:'\n",
    "  \n",
    "  \n",
    "  job_id = submit_id_mapping(\n",
    "  from_db=\"UniProtKB_AC-ID\", to_db=to , ids=[id])\n",
    "\n",
    "  try: \n",
    "    if check_id_mapping_results_ready(job_id):\n",
    "        link = get_id_mapping_results_link(job_id)\n",
    "        results = get_id_mapping_results_search(link)\n",
    "        # Equivalently using the stream endpoint which is more demanding\n",
    "        # on the API and so is less stable:\n",
    "        # results = get_id_mapping_results_stream(link)\n",
    "  except: \n",
    "    continue\n",
    "  #print(results)\n",
    "  if len(results['results'])>0: \n",
    "    df['NEW_ID'][i] = pre + results['results'][0]['to']\n",
    "  else: \n",
    "    df['NEW_ID'][i] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "id": "DzedaL5TJeMc",
    "outputId": "54b2ed12-b83a-4c17-95a5-d51d1cf516b8"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REVBRU35SUfk"
   },
   "source": [
    "Drop rows that don't have a new ID: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDZKWnuGSjc_"
   },
   "outputs": [],
   "source": [
    "df = df.drop(df[df.NEW_ID == 'NA'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NB8M_jasUMd3"
   },
   "source": [
    "Keep only rows whose the target is in the Monarch nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8gAA51YUGVJ"
   },
   "outputs": [],
   "source": [
    "df = df[df['NEW_ID'].isin(list(nodes['id']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF7YO1_cVkrW"
   },
   "source": [
    "Save the Drug-Target dataframe as .csv: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sqLYvmDVkMu"
   },
   "outputs": [],
   "source": [
    "df.to_csv('drug_target_edges.csv', encoding = 'utf-8-sig') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ahz6xJ5tVukC"
   },
   "source": [
    "Create and save a dataframe containing the drug nodes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXCoEgc4VuI9"
   },
   "outputs": [],
   "source": [
    "df_drugs = df[['DRUG_NAME', 'STRUCT_ID']]\n",
    "df_drugs = df_drugs.drop_duplicates()\n",
    "df_drugs.to_csv('drug_nodes.csv', encoding = 'utf-8-sig') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "-3bxb-cDV0eU",
    "outputId": "646b6a30-0c62-493b-cb36-6f743f5994ce"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxofHKzSQmsc"
   },
   "source": [
    "## **Drug-Disease Information**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zG38UZcMNbZR"
   },
   "source": [
    "### **Text to CSV**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7E8sqfLRuPeT"
   },
   "source": [
    "If already saved, run only the cell of this section, otherwise continue:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzIEwIIoZKSO"
   },
   "source": [
    "Create a Dataframe that will contain the Drug-Disease information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOvbXSbK8uVW"
   },
   "outputs": [],
   "source": [
    "column_names = [\"DRUG_ID\", \"DRUG_NAME\", \"DISEASES\", 'PHASE']\n",
    "\n",
    "df = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onfxni42ZRMs"
   },
   "source": [
    "Read the .txt file downloaded from TTD and convert it into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzq2Uki87lvQ"
   },
   "outputs": [],
   "source": [
    "with open('drug_to_disease.txt') as f:\n",
    "  lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5wUPLYV8Zzi"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "id = ''\n",
    "name = ''\n",
    "disease = ''\n",
    "phase = ''\n",
    "\n",
    "for line in lines: \n",
    "  if line.startswith('DRUGNAME'): \n",
    "    result = re.search('\\t(.*)\\n', line)\n",
    "    name = result.group(1)\n",
    "  elif line.startswith('TTDDRUID'): \n",
    "    result = re.search('\\t(.*)\\n', line)\n",
    "    id = result.group(1)\n",
    "  elif line.startswith('INDICATI'): \n",
    "    result = re.search('\\t(.*)\\[', line)\n",
    "    result2 = re.search('\\](.*)', line)\n",
    "    disease = result.group(1) \n",
    "    phase = result2.group(1) \n",
    "    df.loc[i] = [id,name,disease, phase]\n",
    "    i += 1\n",
    "  elif line.startswith('\\n'): \n",
    "    id = ''\n",
    "    name = ''\n",
    "    disease = ''\n",
    "    phase = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "at9bi3JlTDO-",
    "outputId": "11d04418-e299-4063-cc23-a90fe7efb723"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4JVJ8UTughx"
   },
   "outputs": [],
   "source": [
    "df.to_csv('drug_to_disease.csv', encoding = 'utf-8-sig') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tZ8TvX8uijc"
   },
   "source": [
    "Run only this cell if you have already saved the Drug-Disease interactions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Chohm-ot-K8"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('drug_to_disease.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "cFkYZOLiuD5J",
    "outputId": "78bcc07b-9e51-4945-ff84-c3bc8cb8bb31"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2paf44JNj-E"
   },
   "source": [
    "### **Load CSVs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k72QQlyxi1Hf"
   },
   "source": [
    "Load the drug nodes (obtained from Drug Central) and the Monarch nodes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZHLjmycrNq-O"
   },
   "outputs": [],
   "source": [
    "graph_drugs = pd.read_csv('drug_nodes.csv', header=0)\n",
    "nodes = pd.read_csv('graph_nodes_v2022-01-11.csv', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fD9f6eB5jBip"
   },
   "source": [
    "Get list of unique drugs and diseases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hc3FS4i-JRN-"
   },
   "outputs": [],
   "source": [
    "graph_diseases = nodes[nodes['semantic_groups'] == 'DISO']\n",
    "unique_diseases = graph_diseases['name'].unique()\n",
    "unique_dis_id = graph_diseases['id'].unique()\n",
    "unique_diseases = [x.lower() for x in unique_diseases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ksgSy3W4M2kr",
    "outputId": "65a0dcc9-7a71-4078-92be-0f30b2f84230"
   },
   "outputs": [],
   "source": [
    "unique_drugs = graph_drugs['DRUG_NAME'].unique()\n",
    "unique_drugs = [x.lower() for x in unique_drugs]\n",
    "len(unique_drugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4MyvP7LjFrd"
   },
   "source": [
    "At this point you should use SORTA tool (https://sorta.molgeniscloud.org/menu/main/sorta?) to match the IDs of TTD to Human Phenotype Ontology (HPO). The file is also available in the project's Github:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kB63_Gm7Un1y"
   },
   "outputs": [],
   "source": [
    "matched = pd.read_csv('matched.csv', header = 0, delimiter = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "Y28hfIBbUxSe",
    "outputId": "ccf836b1-23d6-4665-9691-14c0a0d273de"
   },
   "outputs": [],
   "source": [
    "matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wrdexd0EjhG_"
   },
   "source": [
    "Select only those IDs with a score greater than 80:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_u0Aw8cVMZn"
   },
   "outputs": [],
   "source": [
    "matched = matched[matched['score'] > 80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXmfDo-njlPB"
   },
   "source": [
    "Create the final ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_YT_IsrWoqm",
    "outputId": "0057146c-65ca-49ef-f070-7906304b321a"
   },
   "outputs": [],
   "source": [
    "matched['ID'] = matched['ontologyTermIRI'].str.split('/obo/').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7CsGgPG6jug6",
    "outputId": "3a9732f0-6d3e-4a66-b6d8-48a659e9d624"
   },
   "outputs": [],
   "source": [
    "new_id = []\n",
    "for i in matched['ID']: \n",
    "  id = re.sub(\"[^0-9a-zA-Z]+\", \":\", i)\n",
    "  new_id.append(id)\n",
    "matched['ID'] = new_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpLcQQM-PC02"
   },
   "source": [
    "### **Merging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5GM54sQnR9u"
   },
   "outputs": [],
   "source": [
    "modified = []\n",
    "for d in df['DISEASES']: \n",
    "  new_string = re.sub(\"[^0-9a-zA-Z]+\", \" \", d)\n",
    "  modified.append(new_string.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYa8gpiyan5a"
   },
   "outputs": [],
   "source": [
    "df['Name'] = modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3ocv7dyhxlu",
    "outputId": "6a576730-3da9-4351-cad1-9535ba89169a"
   },
   "outputs": [],
   "source": [
    "df['Name'] = df['Name'].str.strip()\n",
    "matched['Name'] = matched['Name'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUjLn3ONcXLy"
   },
   "outputs": [],
   "source": [
    "final = pd.merge(df, matched, on = 'Name', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "id": "8vO5GLmRd5DP",
    "outputId": "99a0bbfe-f0f5-41ce-8d12-df10f2248ef9"
   },
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXZ4Ex1Qlfid"
   },
   "outputs": [],
   "source": [
    "final.to_csv('drug_to_disease_merged.csv', encoding = 'utf-8-sig') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yB_V-D8YN-Fb"
   },
   "source": [
    "### **Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dddRFmjAOaQj"
   },
   "outputs": [],
   "source": [
    "final = pd.read_csv('drug_to_disease_merged.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxQb0G8MmBT2"
   },
   "outputs": [],
   "source": [
    "final_filtered = final[final['score'] > 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VC7VqX1RmJah",
    "outputId": "c3f146e3-55d4-47ad-d8e3-e11e1d5575ea"
   },
   "outputs": [],
   "source": [
    "len(final_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 834
    },
    "id": "lL_9JhL8Nd_8",
    "outputId": "890b0826-970e-4356-9f13-febe0f3ed13e"
   },
   "outputs": [],
   "source": [
    "final_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4FLanWcNNRn"
   },
   "outputs": [],
   "source": [
    "column_names = [\"DRUG_ID\", \"DRUG_NAME\", \"DISEASES\", 'PHASE']\n",
    "\n",
    "df = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDTcez3hQoav",
    "outputId": "f6e16bb6-1028-4e78-ba6c-6e287eb2af56"
   },
   "outputs": [],
   "source": [
    "unique_drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1eKl0rnDc2GX",
    "outputId": "6a749f6d-1869-4d46-b6cd-b153ef3926e5"
   },
   "outputs": [],
   "source": [
    "for index, row in final_filtered.iterrows(): \n",
    "  if row['DRUG_NAME'].lower() not in unique_drugs or row['ID'] not in unique_dis_id:\n",
    "   final_filtered = final_filtered.drop(labels = index, axis = 0)\n",
    "len(final_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sMGcZ1bIaX3",
    "outputId": "1497f9aa-0149-4412-8c79-9649856efe9a"
   },
   "outputs": [],
   "source": [
    "for index, row in final_filtered.iterrows(): \n",
    "  drug = row['DRUG_NAME'].lower()\n",
    "  id = graph_drugs[graph_drugs['DRUG_NAME'] == drug]['STRUCT_ID'].values[0]\n",
    "  final_filtered.at[index, 'DRUG_ID'] = id\n",
    "len(final_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CmgCq5ABNu3L",
    "outputId": "205747ea-37b0-420c-d689-f95d212d48e7"
   },
   "outputs": [],
   "source": [
    "final_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gIc_qBHQMBV"
   },
   "outputs": [],
   "source": [
    "final_filtered = final_filtered.drop(labels = ['Unnamed: 0', 'score'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BfA_QwZ1OzFl",
    "outputId": "4d7feb64-6417-4277-9004-5af2e63e84fe"
   },
   "outputs": [],
   "source": [
    "final_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ih0nIgqZqK7"
   },
   "outputs": [],
   "source": [
    "final_filtered.to_csv('drug_disease_edges.csv', encoding = 'utf-8-sig') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "X27brzSjOwNe",
    "XpLcQQM-PC02",
    "yB_V-D8YN-Fb"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
